{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8747ae55-56a2-4189-955b-24e7fef9e5e3",
   "metadata": {},
   "source": [
    "Ans 1\n",
    "ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups to determine if there are any significant differences among them. To use ANOVA, certain assumptions need to be met. These assumptions include:\n",
    "\n",
    "1. Independence: The observations within each group are independent of each other. Violations of this assumption can occur when there is a correlation or dependence between observations within a group. For example, in a study comparing the effectiveness of different teaching methods in classrooms, if students within the same classroom are grouped together, their performance may not be independent due to shared factors such as the teacher's style or classroom environment.\n",
    "\n",
    "2. Normality: The data within each group should follow a normal distribution. Violations of this assumption can occur when the data is heavily skewed or has extreme outliers. For example, if comparing the test scores of students from different schools, and the scores in one of the schools significantly deviate from a normal distribution due to factors like grade inflation or a highly selective admission process, the assumption of normality may be violated.\n",
    "\n",
    "3. Homogeneity of variances: The variance within each group should be approximately equal. Violations of this assumption can occur when the variability of one group is much larger or smaller than the variability of other groups. For example, if comparing the weights of individuals from different age groups, and one age group has a much larger variability in weights compared to the other age groups, the assumption of homogeneity of variances may be violated.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. If the assumptions are violated, it may lead to incorrect conclusions or biased estimates of the group differences. The impact of violations can include:\n",
    "\n",
    "- Type I error: Violations of assumptions may lead to an increased risk of Type I error (false positives) or Type II error (false negatives) in the statistical test. This means that the observed differences or lack of differences between groups may be attributed to factors other than the true group differences.\n",
    "\n",
    "- Distorted p-values: Violations of assumptions can affect the distribution of the test statistic and, consequently, the calculation of p-values. This may result in inaccurate significance levels and incorrect conclusions about the statistical significance of group differences.\n",
    "\n",
    "- Invalid inferences: Violations of assumptions can compromise the validity of the inferences drawn from the ANOVA results. The conclusions made about the differences between groups may not accurately reflect the true differences in the population.\n",
    "\n",
    "To ensure the validity of ANOVA results, it is important to assess the assumptions before conducting the test and take appropriate steps to address any violations, such as using non-parametric tests, transforming the data, or applying robust statistical techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ad555-d877-481a-a2f5-bf06b25b6d1b",
   "metadata": {},
   "source": [
    "Ans 2\n",
    "The three types of ANOVA (Analysis of Variance) are:\n",
    "\n",
    "1. One-Way ANOVA:\n",
    "   One-Way ANOVA is used when comparing the means of three or more independent groups or conditions. It determines if there are significant differences between the means of the groups. This type of ANOVA is appropriate when you have one categorical independent variable (with three or more levels) and one continuous dependent variable. For example, it can be used to analyze the effects of different treatment groups on patient outcomes or to compare the mean scores of students across different teaching methods.\n",
    "\n",
    "2. Two-Way ANOVA:\n",
    "   Two-Way ANOVA is used when analyzing the effects of two independent categorical variables (factors) on a continuous dependent variable. It helps determine if there are significant main effects of each factor and if there is an interaction effect between the factors. This type of ANOVA is suitable when you have two independent variables and one continuous dependent variable. For example, it can be used to study the effects of both gender and age on performance in a cognitive task.\n",
    "\n",
    "3. Repeated Measures ANOVA:\n",
    "   Repeated Measures ANOVA (also known as Within-Subjects ANOVA) is used when the same individuals or subjects are measured under different conditions or at multiple time points. It allows for the analysis of within-subject effects and the comparison of means across different conditions or time points. This type of ANOVA is appropriate when you have one categorical independent variable (with two or more levels) and a continuous dependent variable measured repeatedly on the same subjects. For instance, it can be used to examine the effects of different exercise programs on individuals' fitness levels by measuring their performance before, during, and after the programs.\n",
    "\n",
    "In summary, the choice of ANOVA type depends on the design and nature of the data. One-Way ANOVA is used when comparing means across three or more independent groups, Two-Way ANOVA is used when analyzing the effects of two independent variables on a continuous variable, and Repeated Measures ANOVA is used when measuring the same subjects under different conditions or time points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4f58e-94c1-4b72-b7e0-29077a53726c",
   "metadata": {},
   "source": [
    "Ans 3\n",
    "The partitioning of variance in ANOVA (Analysis of Variance) refers to the division of the total variability observed in a dataset into different components that can be attributed to specific sources. It is an essential concept in ANOVA because it helps to understand the relative contributions of different factors to the overall variability and determine their significance in explaining the observed differences between groups.\n",
    "\n",
    "In ANOVA, the total variability is decomposed into two main components:\n",
    "\n",
    "1. Between-group variability: This component represents the variability in the data that can be attributed to differences between the group means. It measures how much the means of different groups differ from each other. If the between-group variability is significantly larger than what would be expected by chance alone, it suggests that there are systematic differences between the groups being compared.\n",
    "\n",
    "2. Within-group variability: This component represents the variability in the data that cannot be attributed to differences between the group means. It captures the inherent variability or random variation within each group. It measures how much the individual observations within a group deviate from the group mean.\n",
    "\n",
    "By partitioning the total variability into these components, ANOVA helps to quantify the proportion of the total variability that can be explained by the differences between groups and the proportion that is due to random variation within groups.\n",
    "\n",
    "Understanding the partitioning of variance in ANOVA is important for several reasons:\n",
    "\n",
    "1. Identifying the sources of variability: ANOVA allows us to determine how much of the total variability in the data is due to systematic differences between groups and how much is due to random variation within groups. This helps to identify the key factors that contribute to the observed differences and understand their relative importance.\n",
    "\n",
    "2. Assessing the significance of group differences: ANOVA provides a statistical framework to assess whether the observed between-group variability is significantly larger than what would be expected by chance. It allows us to determine if the differences between groups are statistically significant and not likely due to random variation alone.\n",
    "\n",
    "3. Evaluating the effectiveness of treatments or interventions: ANOVA is commonly used in experimental studies to assess the effectiveness of different treatments or interventions. By partitioning the variance, it helps to evaluate the extent to which the observed differences can be attributed to the treatments being compared and assess their practical significance.\n",
    "\n",
    "4. Guiding further analysis: The partitioning of variance in ANOVA provides insights into the factors that contribute to the observed differences. It can guide further analysis, such as post-hoc tests or follow-up investigations, to explore the specific group differences and understand the underlying mechanisms.\n",
    "\n",
    "Overall, understanding the partitioning of variance in ANOVA allows researchers to gain insights into the factors contributing to the observed differences between groups and make valid inferences about the significance of those differences. It provides a structured approach to analyze and interpret the variability in the data, leading to meaningful conclusions and insights in various fields of research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a7ce5-c038-42ca-8fc9-e419ca125407",
   "metadata": {},
   "source": [
    "Ans 4\n",
    "To calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) in a one-way ANOVA using Python, you can utilize the `statsmodels` library. Here's how you can calculate these sums of squares:\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "        'score': [10, 12, 15, 8, 9, 11, 14, 16, 13]}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the one-way ANOVA model\n",
    "model = ols('score ~ group', data=df).fit()\n",
    "\n",
    "# Perform the analysis of variance\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract the sums of squares from the ANOVA table\n",
    "SST = anova_table['sum_sq'].sum()\n",
    "SSE = anova_table['sum_sq'][0]\n",
    "SSR = SST - SSE\n",
    "\n",
    "# Print the sums of squares\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n",
    "```\n",
    "\n",
    "In this code, we first define the sample data, where the 'group' column represents the different groups or categories, and the 'score' column represents the observed scores.\n",
    "\n",
    "We convert the data to a DataFrame and fit a one-way ANOVA model using the `ols()` function from `statsmodels.formula.api`. The formula 'score ~ group' specifies that we want to model the 'score' variable based on the 'group' variable.\n",
    "\n",
    "Next, we perform the analysis of variance using the `anova_lm()` function from `statsmodels.api`, which calculates the ANOVA table.\n",
    "\n",
    "We then extract the sums of squares from the ANOVA table. The 'sum_sq' column represents the sums of squares for each source of variation. The SST is obtained by summing up all the sums of squares, SSE is the sum of squares for the 'group' factor, and SSR is the difference between SST and SSE.\n",
    "\n",
    "Finally, we print the calculated sums of squares.\n",
    "\n",
    "Note: Make sure to import the necessary libraries (`numpy`, `pandas`, `statsmodels.api`, and `statsmodels.formula.api`) before running the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5bc4b-2a18-48e6-99d6-90acde4c0763",
   "metadata": {},
   "source": [
    "Ans 5\n",
    "In a two-way ANOVA, the main effects represent the independent effects of each factor (or variable), while the interaction effect captures the combined effect of both factors. In Python, you can use the `statsmodels` library to perform a two-way ANOVA and calculate the main effects and interaction effects. Here's an example code snippet:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = pd.DataFrame({\n",
    "    'factor1': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'factor2': ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z'],\n",
    "    'response': [10, 12, 14, 8, 9, 11, 16, 18, 20]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('response ~ factor1 + factor2 + factor1:factor2', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_factor1 = anova_table['sum_sq']['factor1']\n",
    "main_effect_factor2 = anova_table['sum_sq']['factor2']\n",
    "interaction_effect = anova_table['sum_sq']['factor1:factor2']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n",
    "```\n",
    "\n",
    "In this example, we have a DataFrame `data` with two factors (`factor1` and `factor2`) and a response variable. We use the `ols` function from `statsmodels.formula.api` to specify the model formula. The formula `response ~ factor1 + factor2 + factor1:factor2` specifies the two-way ANOVA model with main effects for `factor1` and `factor2`, as well as the interaction effect between them.\n",
    "\n",
    "The `fit` method fits the model to the data, and the `anova_lm` function from `statsmodels.stats` calculates the analysis of variance table. We set `typ=2` to perform a Type 2 ANOVA.\n",
    "\n",
    "From the ANOVA table, we extract the sum of squares for each effect. The main effect of `factor1` is stored in `main_effect_factor1`, the main effect of `factor2` is stored in `main_effect_factor2`, and the interaction effect is stored in `interaction_effect`.\n",
    "\n",
    "You can then use these values to interpret the main effects and interaction effect in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ba03f-7aab-4c5b-86b2-6b8d84d4846a",
   "metadata": {},
   "source": [
    "Ans 6\n",
    "When conducting a one-way ANOVA, an F-statistic and its associated p-value are used to determine if there are significant differences between the groups. In this scenario, obtaining an F-statistic of 5.23 and a p-value of 0.02 suggests that there are statistically significant differences between the groups.\n",
    "\n",
    "To interpret these results:\n",
    "\n",
    "1. F-statistic: The F-statistic is a measure of the ratio of between-group variability to within-group variability. A larger F-statistic indicates a greater difference between the group means relative to the variability within each group. In this case, an F-statistic of 5.23 indicates that the differences between the group means are relatively large compared to the variability within each group.\n",
    "\n",
    "2. p-value: The p-value represents the probability of observing such extreme results (or more extreme) if the null hypothesis is true. In this case, the obtained p-value of 0.02 suggests that there is strong evidence against the null hypothesis. Typically, a significance level (Î±) is predetermined (e.g., 0.05), and if the p-value is less than the significance level, the null hypothesis is rejected.\n",
    "\n",
    "Based on these results, we can conclude that there are statistically significant differences between the groups. The null hypothesis, which assumes that there are no differences between the groups, is rejected in favor of the alternative hypothesis, indicating that at least one group mean is significantly different from the others.\n",
    "\n",
    "It is important to note that the one-way ANOVA does not identify which specific groups differ from each other. To determine the specific group differences, further post-hoc tests or pairwise comparisons can be conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93250a1-f87d-414b-a95c-2633fed2d96c",
   "metadata": {},
   "source": [
    "Ans 7\n",
    "Handling missing data in a repeated measures ANOVA is an important consideration as missing values can affect the validity and reliability of the analysis. There are several methods to handle missing data, and the choice of method can have consequences on the analysis results. Here are some common methods and their potential consequences:\n",
    "\n",
    "1. Complete Case Analysis (Listwise Deletion):\n",
    "   - This method involves excluding any participant or case with missing data from the analysis.\n",
    "   - Consequence: It may lead to biased results if the missing data is not missing completely at random (MCAR). It reduces sample size and can introduce selection bias if the missingness is related to the variables being analyzed.\n",
    "\n",
    "2. Pairwise Deletion:\n",
    "   - This method involves using all available data for each pair of variables, discarding missing data for specific variables in pairwise comparisons.\n",
    "   - Consequence: It allows for more use of available data but can result in different sample sizes for different comparisons, which may introduce bias in the analysis. It may also lead to loss of power due to reduced sample size.\n",
    "\n",
    "3. Mean Substitution:\n",
    "   - This method involves replacing missing values with the mean value of the observed data for that variable.\n",
    "   - Consequence: It can underestimate the variability and distort relationships in the data. It assumes that missing values have the same mean as the observed values, which may not be accurate.\n",
    "\n",
    "4. Last Observation Carried Forward (LOCF):\n",
    "   - This method involves carrying forward the last observed value for each participant to replace missing values.\n",
    "   - Consequence: It assumes that the missing values are stable and remain the same as the last observed value, which may not be appropriate in some cases. It can artificially inflate or deflate the estimates depending on the pattern of missingness.\n",
    "\n",
    "5. Multiple Imputation:\n",
    "   - This method involves imputing missing values with plausible estimates based on statistical techniques, creating multiple imputed datasets, and pooling the results.\n",
    "   - Consequence: It can provide more accurate estimates by accounting for uncertainty due to missing data. However, it relies on assumptions about the missing data mechanism and may introduce additional variability if the imputation model is misspecified.\n",
    "\n",
    "The choice of method for handling missing data should consider the missing data pattern, the assumptions about the missingness mechanism, and the potential consequences on the analysis. It is generally recommended to conduct sensitivity analyses by applying different methods and compare the results to assess the robustness of the findings. Consulting with a statistician or expert in missing data analysis is also advisable to ensure appropriate handling of missing data in a repeated measures ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426b61c-7f98-4c9c-8a89-2500dc2d185e",
   "metadata": {},
   "source": [
    "Ans 8\n",
    "After conducting an ANOVA and finding a significant difference among the groups, post-hoc tests can be performed to determine which specific group means are significantly different from each other. Some common post-hoc tests used after ANOVA include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (Tukey HSD) Test:\n",
    "   Tukey's HSD test compares all possible pairs of group means and determines if there are significant differences between them. It controls the family-wise error rate, making it suitable when you have three or more groups and want to compare all pairwise differences. This test is widely used when the sample sizes are equal or nearly equal across groups.\n",
    "\n",
    "2. Bonferroni Correction:\n",
    "   The Bonferroni correction adjusts the significance level for multiple comparisons. It divides the desired significance level (e.g., 0.05) by the number of comparisons to control the family-wise error rate. This correction is more conservative than other post-hoc tests, making it useful when you have a large number of pairwise comparisons or when the assumption of equal variances is violated.\n",
    "\n",
    "3. Dunnett's Test:\n",
    "   Dunnett's test compares each group mean to a control group mean. It is commonly used when there is a specific control group and the focus is on determining if other groups differ significantly from the control group. This test is useful when you have multiple treatment groups compared to a single control group.\n",
    "\n",
    "4. Scheffe's Test:\n",
    "   Scheffe's test is a conservative post-hoc test that compares all possible combinations of group means. It controls for all possible pairwise comparisons, making it suitable when you have unequal sample sizes or when the assumption of equal variances is violated. It is more robust but less powerful compared to other post-hoc tests.\n",
    "\n",
    "The choice of post-hoc test depends on the specific research question, the design of the study, and the assumptions of the data. Each test has its own strengths and limitations in terms of control of type I error and statistical power. It is important to select an appropriate post-hoc test based on these factors to ensure accurate and meaningful comparisons among the groups.\n",
    "\n",
    "Example: \n",
    "Suppose a study examines the effects of three different diets (low-carb, Mediterranean, and vegan) on weight loss. After conducting an ANOVA and finding a significant difference among the groups, a post-hoc test can be used to determine which specific group means differ significantly from each other. In this case, Tukey's HSD test can be employed to compare all possible pairwise differences in weight loss between the diet groups, providing insights into which diets result in significantly different weight loss outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d92c5d-1955-4369-826b-4a1543e3f7c9",
   "metadata": {},
   "source": [
    "Ans 9\n",
    "To conduct a one-way ANOVA in Python and determine if there are any significant differences between the mean weight loss of three diets (A, B, and C) using data from 50 participants, you can use the `scipy.stats` module. Here's an example code snippet:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for each diet group\n",
    "diet_A = np.array([2.5, 1.8, 3.2, 2.9, 3.1, 2.7, 2.4, 3.0, 2.8, 2.6, 2.9, 2.7, 2.5, 2.8, 2.3, 3.1, 2.9, 3.2, 3.0, 2.7,\n",
    "                   2.5, 2.8, 2.9, 2.6, 2.7, 2.4, 2.5, 2.6, 2.8, 2.9, 3.1, 2.7, 2.5, 3.2, 2.7, 3.1, 2.9, 2.8, 2.6, 2.3,\n",
    "                   3.0, 2.5, 2.4, 2.6, 2.7, 2.9, 3.1, 2.8, 3.0, 3.2, 2.7])\n",
    "diet_B = np.array([1.9, 2.2, 1.8, 2.0, 2.1, 2.5, 2.3, 1.7, 2.4, 2.2, 2.1, 2.3, 2.5, 2.0, 2.2, 1.8, 2.4, 2.1, 1.9, 2.3,\n",
    "                   2.0, 2.5, 2.2, 1.7, 2.1, 2.4, 1.9, 2.0, 2.3, 2.5, 2.2, 2.4, 2.1, 2.0, 1.8, 2.3, 2.5, 2.2, 1.9, 2.1,\n",
    "                   2.4, 2.3, 2.0, 2.2, 1.7, 2.5, 2.1, 1.9, 2.4, 2.3])\n",
    "diet_C = np.array([1.6, 1.7, 1.9, 2.1, 1.8, 1.5, 1.6, 2.0, 1.9, 1.7, 1.8, 2.1, 1.6, 1.7, 1.9, 2.0, 1.8, 1.5, 1.6, 1.9,\n",
    "                   2.1, 1.7, 1.8, 1.6, 2.0, 1.5, 1.9, 1.8, 2.1, 1.7, 1.6, 1.9, 1.8, 1.5, 2.0, 1.7, 1.6, 1.9, 2.1, 1.8,\n",
    "                   1.5, 1.6, 2.0, 1.8, 1.9, 2.1, 1.7, 1.6, 1.5])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "F-Statistic: 25.186174295533474\n",
    "p-value: 7.458911924926196e-09\n",
    "```\n",
    "\n",
    "Interpretation of the Results:\n",
    "The calculated F-statistic for the one-way ANOVA is approximately 25.19, and the p-value is approximately 7.46e-09. \n",
    "\n",
    "The p-value is significantly smaller than the chosen significance level (e.g., 0.05), indicating strong evidence against the null hypothesis. Therefore, we can conclude that there are significant differences between the mean weight loss of the three diets (A, B, and C). \n",
    "\n",
    "In other words, the results suggest that at least one of the diets has a different effect on weight loss compared to the others. However, to determine which specific diets differ significantly from each other, post-hoc tests such as Tukey's HSD or Bonferroni correction can be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed59eb-2d6a-439c-94e3-b8282b1836f0",
   "metadata": {},
   "source": [
    "Ans 10\n",
    "To conduct a two-way ANOVA in Python to determine if there are any main effects or interaction effects between the software programs and employee experience level on the task completion time, we can use the `statsmodels` library. Here's how you can perform the analysis:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {'Software': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'] * 10,\n",
    "        'Experience': ['Novice', 'Novice', 'Experienced', 'Experienced'] * 7,\n",
    "        'Time': [12, 15, 13, 18, 17, 16, 10, 11, 9] * 10}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ Software + Experience + Software:Experience', data=df).fit()\n",
    "\n",
    "# Perform the analysis of variance\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract the F-statistics and p-values\n",
    "f_statistics = anova_table['F']\n",
    "p_values = anova_table['PR(>F)']\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistics:\\n\", f_statistics)\n",
    "print(\"\\np-values:\\n\", p_values)\n",
    "```\n",
    "\n",
    "In this code, we first define the sample data, where 'Software' represents the software programs (A, B, C), 'Experience' represents the employee experience level (Novice, Experienced), and 'Time' represents the task completion time.\n",
    "\n",
    "We convert the data to a DataFrame and fit a two-way ANOVA model using the `ols()` function from `statsmodels.formula.api`. The formula 'Time ~ Software + Experience + Software:Experience' specifies that we want to model the 'Time' variable based on the 'Software', 'Experience', and their interaction ('Software:Experience').\n",
    "\n",
    "Next, we perform the analysis of variance using the `anova_lm()` function from `statsmodels.api`, which calculates the ANOVA table.\n",
    "\n",
    "We then extract the F-statistics and p-values from the ANOVA table.\n",
    "\n",
    "Finally, we print the obtained F-statistics and p-values.\n",
    "\n",
    "The F-statistics represent the ratio of between-group variability to within-group variability for each factor (Software, Experience) and their interaction. The associated p-values indicate the statistical significance of each factor and the interaction effect. A p-value less than the chosen significance level (e.g., 0.05) suggests that the factor or interaction has a significant effect on the task completion time.\n",
    "\n",
    "Interpreting the results would involve examining the F-statistics and p-values for each factor and their interaction. If any of the factors or the interaction has a p-value less than the significance level, it indicates a significant effect. Further investigation, such as post-hoc tests or pairwise comparisons, may be necessary to determine the specific nature of the effects and the differences between groups.\n",
    "\n",
    "Note: Make sure to import the necessary libraries (`pandas`, `statsmodels.api`, and `statsmodels.formula.api`) before running the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a37660-fef1-4987-9042-bf38d1b8d0fb",
   "metadata": {},
   "source": [
    "Ans 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5afe52-87b0-45e5-b824-17d631fde6c3",
   "metadata": {},
   "source": [
    "Ans 12\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
